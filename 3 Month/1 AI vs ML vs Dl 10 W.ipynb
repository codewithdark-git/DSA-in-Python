{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `AI` vs `ML` vs `DL`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Artificial Intelligence (AI)**\n",
    "**Definition**:  \n",
    "AI is the broad field of creating machines capable of performing tasks that typically require human intelligence, such as problem-solving, reasoning, understanding language, and recognizing objects.\n",
    "\n",
    "**Key Techniques**:\n",
    "- **Rule-Based Systems**: Early AI systems where humans manually encoded knowledge (e.g., expert systems).\n",
    "- **Search Algorithms**: Used in games like chess (e.g., Alpha-Beta pruning).\n",
    "- **Natural Language Processing (NLP)**: For understanding and generating human language (e.g., ChatGPT).\n",
    "- **Computer Vision**: Recognizing objects in images (e.g., facial recognition).\n",
    "- **Robotics**: AI for control and perception in robots.\n",
    "\n",
    "**History**:\n",
    "- **1950s**: AI as a formal concept begins with Alan Turing's famous question, \"Can machines think?\" and the Turing Test.\n",
    "- **1956**: The term \"Artificial Intelligence\" is coined at the Dartmouth Conference.\n",
    "- **1950s-1980s**: AI mainly focused on symbolic reasoning, expert systems, and rule-based approaches.\n",
    "- **1990s-2000s**: AI struggled with complexity, leading to an \"AI Winter\" (a period of reduced funding and interest).\n",
    "\n",
    "**Boom Level**:  \n",
    "AI is **booming now** more than ever, driven by the success of ML and DL technologies. Companies are using AI in autonomous vehicles, virtual assistants (like Siri and Alexa), and advanced robotics.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Machine Learning (ML)**\n",
    "**Definition**:  \n",
    "Machine Learning is a subset of AI where machines learn from data without being explicitly programmed. Instead of following hardcoded rules, they use data-driven approaches to make decisions or predictions.\n",
    "\n",
    "**Key Techniques**:\n",
    "- **Supervised Learning**: Models are trained on labeled data (e.g., regression, classification).\n",
    "- **Unsupervised Learning**: Models find hidden patterns from unlabeled data (e.g., clustering, dimensionality reduction).\n",
    "- **Reinforcement Learning**: Agents learn by interacting with an environment and receiving feedback (rewards/punishments).\n",
    "- **Common Algorithms**:\n",
    "  - **Linear Regression**: Predicts continuous values.\n",
    "  - **Logistic Regression**: Binary classification (yes/no, spam/not spam).\n",
    "  - **Decision Trees**: Tree-based decision making.\n",
    "  - **Support Vector Machines (SVMs)**: Classify data by finding the hyperplane.\n",
    "  - **K-Nearest Neighbors (KNN)**: Classifies based on neighboring data points.\n",
    "  \n",
    "**History**:\n",
    "- **1950s-1970s**: Early ML algorithms like perceptrons and decision trees were developed.\n",
    "- **1980s-1990s**: With improved hardware, algorithms like SVMs and ensemble methods gained popularity. ML moved away from symbolic AI to data-driven approaches.\n",
    "- **2000s**: ML began integrating with real-world applications like recommendation systems (Netflix, Amazon).\n",
    "\n",
    "**Boom Level**:  \n",
    "ML **boomed in the 2010s**, especially with the rise of large datasets and better computational power (GPUs). ML powers everything from search engines to fraud detection to personalized recommendations.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Deep Learning (DL)**\n",
    "**Definition**:  \n",
    "Deep Learning is a subset of ML that uses **neural networks** with multiple layers (hence \"deep\") to model complex patterns in data. It's inspired by the human brain's structure and is particularly useful in tasks like image recognition, natural language processing, and game playing.\n",
    "\n",
    "**Key Techniques**:\n",
    "- **Artificial Neural Networks (ANNs)**: Basic form of a neural network with one or two layers.\n",
    "- **Convolutional Neural Networks (CNNs)**: Primarily used for image-related tasks (e.g., image classification).\n",
    "- **Recurrent Neural Networks (RNNs)**: Used for sequential data like time series or text.\n",
    "- **Generative Adversarial Networks (GANs)**: Used to generate new data by pitting two networks against each other (one generates data, the other evaluates it).\n",
    "- **Transformers**: Used for language models (e.g., GPT, BERT).\n",
    "\n",
    "**History**:\n",
    "- **1940s-1960s**: The concept of neural networks began with simple models like the perceptron.\n",
    "- **1980s**: Backpropagation was developed, allowing better training of neural networks, but deep networks were not feasible due to hardware limitations.\n",
    "- **2010s**: The **\"Deep Learning Boom\"** began due to improvements in computing power (GPUs), the availability of large datasets, and algorithmic innovations like CNNs (e.g., AlexNet, 2012).\n",
    "\n",
    "**Boom Level**:  \n",
    "DL is currently **the hottest field** in AI, especially after achieving groundbreaking results in areas like computer vision (e.g., autonomous vehicles), NLP (e.g., ChatGPT, Google’s BERT), and gaming (e.g., AlphaGo).\n",
    "\n",
    "---\n",
    "\n",
    "### **Comparison and Interrelation**:\n",
    "\n",
    "| Aspect            | Artificial Intelligence (AI)          | Machine Learning (ML)                 | Deep Learning (DL)                   |\n",
    "|-------------------|---------------------------------------|---------------------------------------|--------------------------------------|\n",
    "| **Definition**     | Creating intelligent systems         | Learning from data without explicit programming | ML technique using neural networks for large-scale data |\n",
    "| **Key Focus**      | Mimic human intelligence              | Learning patterns from data           | Modeling complex patterns using neural networks |\n",
    "| **Techniques**     | Rule-based systems, NLP, vision, robotics | Supervised, Unsupervised, Reinforcement Learning | CNNs, RNNs, GANs, Transformers        |\n",
    "| **Data Needs**     | Can work without large data           | Requires large datasets               | Requires massive datasets and computing power |\n",
    "| **Use Cases**      | Virtual assistants, game playing      | Spam filters, recommendations         | Image classification, language models, self-driving cars |\n",
    "| **Boom Period**    | 1950s-present (explosion in 2010s)    | 1990s-present (boomed in 2010s)       | 2010s-present (deep boom post-2012)  |\n",
    "\n",
    "### **Boom Phases**:\n",
    "- **AI Boom**: While AI as a field started in the 1950s, the true boom happened after 2010 with the integration of ML and DL technologies.\n",
    "- **ML Boom**: Gained massive traction in the 2010s due to data availability, cheaper storage, and faster processors (GPUs).\n",
    "- **DL Boom**: Started around 2012, when AlexNet (a CNN) won the ImageNet competition, making neural networks mainstream. This boom is still ongoing, driven by large models (GPT-4, OpenAI's advancements, Google DeepMind).\n",
    "\n",
    "### **Current Level of Adoption**:\n",
    "- **AI**: Used across various industries (healthcare, finance, retail) with applications in robotics, virtual assistants, and autonomous systems.\n",
    "- **ML**: Almost everywhere, from fraud detection to personalized ads, to recommendation engines, and predictive analytics.\n",
    "- **DL**: Cutting-edge DL models power the most advanced technologies like autonomous cars, complex language models (ChatGPT), and AI-driven art.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary of AI, ML, DL Relationship:\n",
    "- **AI**: The overarching field that includes ML, DL, robotics, NLP, and more.\n",
    "- **ML**: A subset of AI that focuses on using data to improve task performance.\n",
    "- **DL**: A subset of ML that specifically uses deep neural networks for complex pattern recognition and large-scale data analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI simulates human intelligence to perform tasks and make decisions. <br>\n",
    "ML is a subset of AI that uses algorithms to learn patterns from data. <br>\n",
    "DL is a subset of ML that employs artificial neural networks for complex tasks. <br>\n",
    "AI may or may not require large datasets; it can use predefined rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several types of Machine Learning (ML), categorized based on how the learning process happens and how the algorithm interacts with the data. Below is a detailed breakdown of the major types of ML:\n",
    "\n",
    "### 1. **Supervised Learning**\n",
    "\n",
    "#### Definition:\n",
    "In supervised learning, the model learns from labeled data, where each data point is associated with a correct output (label). The goal is to map input features to output labels based on training data. Once trained, the model can predict labels for new, unseen data.\n",
    "\n",
    "#### Key Components:\n",
    "- **Input**: Labeled data (input-output pairs).\n",
    "- **Output**: Predicted labels or values for new data points.\n",
    "- **Goal**: Minimize the difference between the predicted output and the actual output (label).\n",
    "\n",
    "#### Common Algorithms:\n",
    "- **Linear Regression**: Used for predicting a continuous variable (e.g., predicting house prices based on area).\n",
    "- **Logistic Regression**: Used for binary classification problems (e.g., predicting whether an email is spam or not).\n",
    "- **Decision Trees**: A tree-like model for decision-making where each node represents a decision rule.\n",
    "- **Support Vector Machines (SVMs)**: A classifier that finds the optimal hyperplane to separate data into classes.\n",
    "- **K-Nearest Neighbors (KNN)**: Classifies data points based on the class of their nearest neighbors.\n",
    "- **Random Forest**: An ensemble of decision trees that combines their predictions to improve accuracy.\n",
    "- **Neural Networks**: Used for more complex tasks, like image or speech recognition.\n",
    "\n",
    "#### Example:\n",
    "- **Email Spam Detection**: A model is trained on a dataset of labeled emails (spam/not spam). The features might be the words in the email, and the label is whether it's spam or not. Once trained, the model can classify new emails as spam or not.\n",
    "\n",
    "#### Use Cases:\n",
    "- Image classification\n",
    "- Medical diagnosis (predicting disease)\n",
    "- Sentiment analysis\n",
    "- Predicting stock prices\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Unsupervised Learning**\n",
    "\n",
    "#### Definition:\n",
    "In unsupervised learning, the model is trained on data without labeled outputs. The goal is to discover patterns or structure in the data. Unsupervised learning is used for problems where we don't know what the output should look like.\n",
    "\n",
    "#### Key Components:\n",
    "- **Input**: Unlabeled data (no associated output labels).\n",
    "- **Output**: Discover hidden patterns, clusters, or relationships in the data.\n",
    "- **Goal**: Group similar data points or reduce the complexity of data without supervision.\n",
    "\n",
    "#### Common Algorithms:\n",
    "- **Clustering**:\n",
    "  - **K-Means**: Divides the data into `K` clusters where each data point belongs to the cluster with the nearest mean.\n",
    "  - **Hierarchical Clustering**: Builds a hierarchy of clusters by either splitting or merging clusters step by step.\n",
    "  - **DBSCAN**: A density-based clustering algorithm that groups together points that are closely packed.\n",
    "- **Dimensionality Reduction**:\n",
    "  - **Principal Component Analysis (PCA)**: Reduces the number of features while maintaining the most important information.\n",
    "  - **t-SNE**: Useful for visualizing high-dimensional data in 2D or 3D by reducing its dimensionality.\n",
    "  - **Autoencoders**: A type of neural network that reduces the dimensionality of data by learning a compressed representation.\n",
    "  \n",
    "#### Example:\n",
    "- **Customer Segmentation**: A company might want to segment its customers based on their buying behavior. With unsupervised learning, you can group customers into different segments without having any predefined labels.\n",
    "\n",
    "#### Use Cases:\n",
    "- Market basket analysis (finding items frequently bought together)\n",
    "- Anomaly detection (fraud detection)\n",
    "- Customer segmentation\n",
    "- Data compression\n",
    "- Recommendation systems (discovering similarities between users or products)\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Reinforcement Learning (RL)**\n",
    "\n",
    "#### Definition:\n",
    "In reinforcement learning, an agent learns to make decisions by interacting with an environment. The agent performs actions and receives feedback in the form of rewards or penalties. The goal is to maximize cumulative rewards over time.\n",
    "\n",
    "#### Key Components:\n",
    "- **Agent**: The learner or decision-maker.\n",
    "- **Environment**: The world with which the agent interacts.\n",
    "- **Actions**: The set of moves or decisions the agent can make.\n",
    "- **State**: The current situation or configuration of the environment.\n",
    "- **Reward**: Feedback from the environment that guides learning.\n",
    "\n",
    "#### Common Algorithms:\n",
    "- **Q-Learning**: A value-based algorithm where the agent learns the expected utility (reward) of actions in different states.\n",
    "- **Deep Q-Networks (DQN)**: Combines Q-Learning with deep learning to solve more complex problems, such as video games.\n",
    "- **Policy Gradient Methods**: Directly optimize the policy (the mapping from states to actions) rather than the value of actions.\n",
    "- **Proximal Policy Optimization (PPO)**: A modern policy gradient method used in complex environments.\n",
    "  \n",
    "#### Example:\n",
    "- **Game Playing**: In video games like chess or Go, the agent plays the game by interacting with the environment (the game board) and receives rewards (winning the game). It learns the best strategies over time by trial and error.\n",
    "\n",
    "#### Use Cases:\n",
    "- Self-driving cars (learning to navigate roads safely)\n",
    "- Robotics (teaching robots to complete tasks)\n",
    "- Game playing (AlphaGo, OpenAI's Dota 2 bot)\n",
    "- Autonomous systems (drones, industrial control)\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Semi-Supervised Learning**\n",
    "\n",
    "#### Definition:\n",
    "Semi-supervised learning is a hybrid approach that lies between supervised and unsupervised learning. It uses a small amount of labeled data combined with a large amount of unlabeled data. The labeled data guides the learning process, while the model extracts additional information from the unlabeled data.\n",
    "\n",
    "#### Key Components:\n",
    "- **Input**: A mix of labeled and unlabeled data.\n",
    "- **Output**: Predicted labels for new, unseen data points.\n",
    "- **Goal**: Improve learning accuracy by leveraging a large amount of unlabeled data with only a small amount of labeled data.\n",
    "\n",
    "#### Common Algorithms:\n",
    "- **Self-training**: A model is trained on the small labeled dataset and then used to label the unlabeled data iteratively.\n",
    "- **Co-training**: Uses multiple models trained on different views of the data to label the unlabeled data.\n",
    "- **Transductive SVM**: An extension of SVMs that takes into account both labeled and unlabeled data to optimize classification.\n",
    "  \n",
    "#### Example:\n",
    "- **Image Classification**: If you have a small set of labeled images (e.g., cat vs. dog) but a large dataset of unlabeled images, semi-supervised learning can help improve classification by leveraging the unlabeled images.\n",
    "\n",
    "#### Use Cases:\n",
    "- Speech recognition (where labeling every sound sample is costly)\n",
    "- Text classification (news articles, customer reviews)\n",
    "- Medical image classification (where expert labeling is expensive)\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Self-Supervised Learning**\n",
    "\n",
    "#### Definition:\n",
    "Self-supervised learning is a type of machine learning where the model generates its own labels from the input data. It doesn't require manually labeled data. Instead, the model learns to predict part of the input data from other parts of the data.\n",
    "\n",
    "#### Key Components:\n",
    "- **Input**: Raw data where the model generates labels from within the data itself.\n",
    "- **Output**: The model learns to predict missing parts or features of the data.\n",
    "- **Goal**: Train models that can understand data representations without human-provided labels.\n",
    "\n",
    "#### Common Algorithms:\n",
    "- **Contrastive Learning**: Teaches the model to distinguish between similar and dissimilar data points by creating positive and negative pairs.\n",
    "- **Masked Language Models (MLMs)**: Used in models like BERT, where certain words are masked and the model learns to predict them.\n",
    "- **Autoencoders**: Neural networks that reconstruct input data from compressed representations, learning meaningful feature representations.\n",
    "\n",
    "#### Example:\n",
    "- **Language Models**: In models like BERT and GPT, the task is to predict missing words in sentences (e.g., \"The cat is [MASK] on the mat\"). The model learns language representations by training on massive amounts of text.\n",
    "\n",
    "#### Use Cases:\n",
    "- Pre-training large language models (like BERT, GPT)\n",
    "- Visual representation learning (e.g., learning features for images without explicit labels)\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Online Learning**\n",
    "\n",
    "#### Definition:\n",
    "Online learning, also known as incremental learning, involves updating the model continuously as new data becomes available, rather than training on a fixed dataset all at once. This is particularly useful when data is received in a stream or the environment is constantly changing.\n",
    "\n",
    "#### Key Components:\n",
    "- **Input**: A continuous stream of data.\n",
    "- **Output**: Updated model predictions based on new data.\n",
    "- **Goal**: Adapt to new information as it arrives, improving the model incrementally.\n",
    "\n",
    "#### Common Algorithms:\n",
    "- **Perceptron**: A basic online learning algorithm where weights are updated with each data point.\n",
    "- **SGD (Stochastic Gradient Descent)**: An optimization method that updates the model’s parameters after processing each data point.\n",
    "\n",
    "#### Example:\n",
    "- **Stock Market Prediction**: As new stock prices become available, the model continuously updates its parameters to predict future stock prices.\n",
    "\n",
    "#### Use Cases:\n",
    "- Real-time recommendation systems (Netflix, YouTube)\n",
    "- Spam filtering (adapt to new types of spam)\n",
    "- Predictive maintenance in industrial machines\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion:\n",
    "Different types of machine learning solve different kinds of problems, ranging from well-defined tasks with labeled data (supervised learning) to discovering hidden patterns in raw data (unsupervised learning) and learning from interaction (reinforcement learning). Depending on the task, the type of data, and the availability of labels, different types of machine learning can be applied.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
